# Critical Thinking in the Age of AI

---


## Different things we mean by AI

* **Artificial Intelligence (AI)**<br>
  _systems for performing tasks that typically require human intelligence_

* **Machine Learning (ML)**<br>
  _systems that derive patterns from data and use those patterns to arrive at predictions or decisions_

* **Deep Learning (DL)** <br>
  _ML techniques that use artificial neural nets with multiple layers to learn complex patterns_

* "AI" today is almost always referring to something that comes under the heading of DL

* "AI" often means LLMs and generative AI.

---


## Generative LLMs

* Not all LLMs are "generative" (BERT, ~T5)

* Generative LLMs (GPT, Claude, Gemini, LLaMA) are the GPT-style (decoder-only, autoregressive) ones.
  * prompt-based -- "chatbots"

* GPT-style models are very strong in tasks like text completion, creative writing, translation, and the conversation game

* They're the most hyped, the most superficially impressive, the easiest to use and the most easily available

* They're also the most fraught with danger and misunderstanding

::: Much of the commentary on "AI" that I see (both from boosters and from skeptics) slides back and forth across these distinctions, and many of the considerations in terms of opportunities and dangers apply highly differentially across these distinctions.

* The nature of these autoregressive architectures is that they produce something very plausible and confident sounding.

---


## Dangers of GPT-style Architectures for Research

* "Hallucinations" and fabrications

* Elision of subtleties, contradictions, and limitations

* Bias Amplification

* Intellectual Property and Plagiarism

* Reproducibility Problems

* Ethical and Consent Issues


:::

Lately seeing a lot of folks who want to use generative LLMs to do analytic research

* "Hallucinations" and fabrications
  it's all hallucinations
  AI models can generate convincing but entirely false information, including fake citations, non-existent studies, and fabricated data. This is particularly dangerous in research where accuracy is paramount, as these hallucinations can appear credible and may be difficult to detect without thorough verification.  

* Elision of subtleties, contradictions, and limitations

* Bias Amplification

* Intellectual Property and Plagiarism
Generative AI may reproduce copyrighted content or closely paraphrase existing work without proper attribution. This raises serious concerns about academic integrity and can lead to unintentional plagiarism, especially when researchers don't adequately verify or cite AI-generated content.

* Reproducibility Problems

* Ethical and Consent Issues
